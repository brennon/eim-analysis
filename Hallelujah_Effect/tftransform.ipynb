{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# \"Hallelujah Effect\" Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "pip uninstall -y google-cloud-dataflow\n",
    "pip install --upgrade --force tensorflow_transform==0.6.0 apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Restart the kernel</b> after you do a pip install (click on the <b>Reset</b> button in Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-airflow==1.9.0\n",
      "apache-beam==2.5.0\n",
      "tensorflow==1.8.0\n",
      "tensorflow-transform==0.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "pip freeze | grep -e 'flow\\|beam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set bucket, project, and region\n",
    "BUCKET = 'eim-muse'\n",
    "PROJECT = 'eim-muse'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Retrieve and Subset Datasource\n",
    "\n",
    "Get data from BigQuery but defer filtering, etc. to Beam. Data in BigQuery has been pre-processed with Dataprep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1=train 2=valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "  `eim-muse.hallelujah_effect.full_hallelujah_trials_cleaned`\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} WHERE MOD(FARM_FINGERPRINT(id), 10) < 7\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} WHERE MOD(FARM_FINGERPRINT(id), 10) >= 8\".format(base_query)\n",
    "  else:\n",
    "      query = \"{0} WHERE MOD(FARM_FINGERPRINT(id), {1}) = {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>concentration</th>\n",
       "      <th>musical_expertise</th>\n",
       "      <th>artistic</th>\n",
       "      <th>fault</th>\n",
       "      <th>imagination</th>\n",
       "      <th>lazy</th>\n",
       "      <th>nervous</th>\n",
       "      <th>outgoing</th>\n",
       "      <th>reserved</th>\n",
       "      <th>...</th>\n",
       "      <th>music_pref_none</th>\n",
       "      <th>music_pref_hiphop</th>\n",
       "      <th>music_pref_dance</th>\n",
       "      <th>music_pref_world</th>\n",
       "      <th>music_pref_rock</th>\n",
       "      <th>music_pref_pop</th>\n",
       "      <th>music_pref_classical</th>\n",
       "      <th>music_pref_jazz</th>\n",
       "      <th>music_pref_folk</th>\n",
       "      <th>music_pref_traditional_irish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.411765</td>\n",
       "      <td>3.966221</td>\n",
       "      <td>2.541715</td>\n",
       "      <td>2.353326</td>\n",
       "      <td>3.013545</td>\n",
       "      <td>3.765222</td>\n",
       "      <td>3.564988</td>\n",
       "      <td>3.327657</td>\n",
       "      <td>3.378741</td>\n",
       "      <td>3.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.760534</td>\n",
       "      <td>0.758038</td>\n",
       "      <td>0.936682</td>\n",
       "      <td>0.814311</td>\n",
       "      <td>0.745692</td>\n",
       "      <td>0.846546</td>\n",
       "      <td>0.788906</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.522440</td>\n",
       "      <td>0.656813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.327035</td>\n",
       "      <td>0.386953</td>\n",
       "      <td>0.386953</td>\n",
       "      <td>0.474858</td>\n",
       "      <td>0.493270</td>\n",
       "      <td>0.499554</td>\n",
       "      <td>0.410426</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.287902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.250000</td>\n",
       "      <td>3.991266</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.824561</td>\n",
       "      <td>3.659389</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.228070</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.991266</td>\n",
       "      <td>2.529880</td>\n",
       "      <td>2.353712</td>\n",
       "      <td>3.144737</td>\n",
       "      <td>3.824561</td>\n",
       "      <td>3.659389</td>\n",
       "      <td>3.596491</td>\n",
       "      <td>3.228070</td>\n",
       "      <td>3.117904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.353712</td>\n",
       "      <td>3.144737</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.596491</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.117904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  concentration  musical_expertise   artistic      fault  \\\n",
       "count  34.000000      34.000000          34.000000  34.000000  34.000000   \n",
       "mean   23.411765       3.966221           2.541715   2.353326   3.013545   \n",
       "std    11.760534       0.758038           0.936682   0.814311   0.745692   \n",
       "min     5.000000       2.000000           1.000000   1.000000   1.000000   \n",
       "25%    17.250000       3.991266           2.000000   2.000000   3.000000   \n",
       "50%    21.000000       3.991266           2.529880   2.353712   3.144737   \n",
       "75%    31.750000       4.000000           3.000000   2.353712   3.144737   \n",
       "max    56.000000       5.000000           5.000000   4.000000   4.000000   \n",
       "\n",
       "       imagination       lazy    nervous   outgoing   reserved  \\\n",
       "count    34.000000  34.000000  34.000000  34.000000  34.000000   \n",
       "mean      3.765222   3.564988   3.327657   3.378741   3.000128   \n",
       "std       0.846546   0.788906   0.842047   0.522440   0.656813   \n",
       "min       1.000000   1.000000   1.000000   2.000000   2.000000   \n",
       "25%       3.824561   3.659389   3.000000   3.228070   3.000000   \n",
       "50%       3.824561   3.659389   3.596491   3.228070   3.117904   \n",
       "75%       4.000000   4.000000   3.596491   4.000000   3.117904   \n",
       "max       5.000000   5.000000   5.000000   4.000000   4.000000   \n",
       "\n",
       "                   ...               music_pref_none  music_pref_hiphop  \\\n",
       "count              ...                     34.000000          34.000000   \n",
       "mean               ...                      0.029412           0.117647   \n",
       "std                ...                      0.171499           0.327035   \n",
       "min                ...                      0.000000           0.000000   \n",
       "25%                ...                      0.000000           0.000000   \n",
       "50%                ...                      0.000000           0.000000   \n",
       "75%                ...                      0.000000           0.000000   \n",
       "max                ...                      1.000000           1.000000   \n",
       "\n",
       "       music_pref_dance  music_pref_world  music_pref_rock  music_pref_pop  \\\n",
       "count         34.000000         34.000000        34.000000       34.000000   \n",
       "mean           0.176471          0.176471         0.323529        0.617647   \n",
       "std            0.386953          0.386953         0.474858        0.493270   \n",
       "min            0.000000          0.000000         0.000000        0.000000   \n",
       "25%            0.000000          0.000000         0.000000        0.000000   \n",
       "50%            0.000000          0.000000         0.000000        1.000000   \n",
       "75%            0.000000          0.000000         1.000000        1.000000   \n",
       "max            1.000000          1.000000         1.000000        1.000000   \n",
       "\n",
       "       music_pref_classical  music_pref_jazz  music_pref_folk  \\\n",
       "count             34.000000        34.000000        34.000000   \n",
       "mean               0.411765         0.205882         0.029412   \n",
       "std                0.499554         0.410426         0.171499   \n",
       "min                0.000000         0.000000         0.000000   \n",
       "25%                0.000000         0.000000         0.000000   \n",
       "50%                0.000000         0.000000         0.000000   \n",
       "75%                1.000000         0.000000         0.000000   \n",
       "max                1.000000         1.000000         1.000000   \n",
       "\n",
       "       music_pref_traditional_irish  \n",
       "count                     34.000000  \n",
       "mean                       0.088235  \n",
       "std                        0.287902  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.000000  \n",
       "75%                        0.000000  \n",
       "max                        1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = bq.Query(query).execute().result().to_dataframe()\n",
    "df_valid.head()\n",
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'age', u'concentration', u'hearing_impairments',\n",
       "       u'musical_expertise', u'nationality', u'artistic', u'fault',\n",
       "       u'imagination', u'lazy', u'nervous', u'outgoing', u'reserved',\n",
       "       u'stress', u'thorough', u'trusting', u'activity', u'engagement',\n",
       "       u'familiarity', u'like_dislike', u'positivity', u'tension', u'sex',\n",
       "       u'hallelujah_reaction', u'location', u'language', u'music_pref_none',\n",
       "       u'music_pref_hiphop', u'music_pref_dance', u'music_pref_world',\n",
       "       u'music_pref_rock', u'music_pref_pop', u'music_pref_classical',\n",
       "       u'music_pref_jazz', u'music_pref_folk',\n",
       "       u'music_pref_traditional_irish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create ML dataset using tf.transform and Dataflow\n",
    "\n",
    "Let's use Cloud Dataflow to read in the BigQuery data and write it out as CSV files. Along the way, let's use tf.transform to do scaling and transforming. Using tf.transform allows us to save the metadata to ensure that the appropriate transformations get carried out during prediction as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%writefile requirements.txt\n",
    "tensorflow-transform==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job hallelujah-effect-features-180701-182637 ... hang on\n",
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: gs://eim-muse/analysis/hallelujah-effect/preproc_tft/tmp/tftransform_tmp/b54cc5e0360145d7bfaca7e728c371a6/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: gs://eim-muse/analysis/hallelujah-effect/preproc_tft/tmp/tftransform_tmp/b54cc5e0360145d7bfaca7e728c371a6/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: gs://eim-muse/analysis/hallelujah-effect/preproc_tft/tmp/tftransform_tmp/579242c4364340c7a4782b9bff86f54f/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: gs://eim-muse/analysis/hallelujah-effect/preproc_tft/tmp/tftransform_tmp/579242c4364340c7a4782b9bff86f54f/saved_model.pb\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 18:26:37.348956. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "\n",
    "def is_valid(inputs):\n",
    "    try:\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "float_features = [\n",
    "    'activity',\n",
    "    'age',\n",
    "    'artistic',\n",
    "    'concentration',\n",
    "    'engagement',\n",
    "    'familiarity',\n",
    "    'fault',\n",
    "    'imagination',\n",
    "    'lazy',\n",
    "    'like_dislike',\n",
    "    'musical_expertise',\n",
    "    'nervous',\n",
    "    'outgoing',\n",
    "    'positivity',\n",
    "    'reserved',\n",
    "    'stress',\n",
    "    'tension',\n",
    "    'thorough',\n",
    "    'trusting'\n",
    "]\n",
    "\n",
    "boolean_features = [\n",
    "    'hallelujah_reaction',\n",
    "    'hearing_impairments',\n",
    "    'music_pref_classical',\n",
    "    'music_pref_dance',\n",
    "    'music_pref_folk',\n",
    "    'music_pref_hiphop',\n",
    "    'music_pref_jazz',\n",
    "    'music_pref_none',\n",
    "    'music_pref_pop',\n",
    "    'music_pref_rock',\n",
    "    'music_pref_traditional_irish',\n",
    "    'music_pref_world'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'language',\n",
    "    'location',\n",
    "    'nationality',\n",
    "    'sex'\n",
    "]\n",
    "\n",
    "def preprocess_tft(inputs):\n",
    "    import datetime\n",
    "    result = {}\n",
    "    \n",
    "    for feature in float_features:\n",
    "        result[feature] = tft.scale_to_0_1(inputs[feature])\n",
    "    \n",
    "    for feature in boolean_features:\n",
    "        result[feature] = tf.cast(inputs[feature], tf.int64)\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        result[feature] = tf.identity(inputs[feature])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def preprocess(in_test_mode, EVERY_N=None):\n",
    "  import os\n",
    "  import os.path\n",
    "  import tempfile\n",
    "  from apache_beam.io import tfrecordio\n",
    "  from tensorflow_transform.coders import example_proto_coder\n",
    "  from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "  from tensorflow_transform.tf_metadata import dataset_schema\n",
    "  from tensorflow_transform.beam import tft_beam_io\n",
    "  from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "  job_name = 'hallelujah-effect-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "  if in_test_mode:\n",
    "    import shutil\n",
    "    print 'Launching local job ... hang on'\n",
    "    OUTPUT_DIR = './preproc_tft'\n",
    "    shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "    \n",
    "  else:\n",
    "    print 'Launching Dataflow job {} ... hang on'.format(job_name)\n",
    "    OUTPUT_DIR = 'gs://{0}/analysis/hallelujah-effect/preproc_tft/'.format(BUCKET)\n",
    "    import subprocess\n",
    "    subprocess.call('gsutil rm -r {}'.format(OUTPUT_DIR).split())\n",
    "  \n",
    "  # Configure Beam pipeline options\n",
    "  options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': job_name,\n",
    "    'project': PROJECT,\n",
    "    'max_num_workers': 24,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True,\n",
    "    'requirements_file': 'requirements.txt'\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "  if in_test_mode:\n",
    "    RUNNER = 'DirectRunner'\n",
    "  else:\n",
    "    RUNNER = 'DataflowRunner'\n",
    "\n",
    "  # Setup metadata\n",
    "  raw_data_schema = {\n",
    "    colname : dataset_schema.ColumnSchema(tf.string, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in categorical_features\n",
    "  }\n",
    "  raw_data_schema.update({\n",
    "      colname : dataset_schema.ColumnSchema(tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in float_features\n",
    "    })\n",
    "  raw_data_schema.update({\n",
    "      colname : dataset_schema.ColumnSchema(tf.int64, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in boolean_features\n",
    "    })\n",
    "  raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema(raw_data_schema))\n",
    "  \n",
    "  # run Beam  \n",
    "  with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "    with beam_impl.Context(temp_dir=os.path.join(OUTPUT_DIR, 'tmp')):\n",
    "      \n",
    "      # Write the raw data metadata to disk\n",
    "      # Without the overloaded operators: p.apply(tft_beam_io.WriteMetadata(os.path.join(OUTPUT_DIR, 'metadata/rawdata_metadata'), raw_data_metadata)\n",
    "      _ = (raw_data_metadata\n",
    "        | 'WriteInputMetadata' >> tft_beam_io.WriteMetadata(\n",
    "            os.path.join(OUTPUT_DIR, 'metadata/rawdata_metadata'),\n",
    "            pipeline=p))\n",
    "           \n",
    "      # Analyze and transform training data\n",
    "      this_query = create_query(1, EVERY_N)\n",
    "      \n",
    "      # Read in training data from BigQuery table\n",
    "      raw_data = (p\n",
    "        # Get raw training data from BigQuery\n",
    "        | 'train_read' >> beam.io.Read(beam.io.BigQuerySource(query=this_query, use_standard_sql=True))\n",
    "        # Use our is_valid function to only retain valid examples from training data\n",
    "        | 'train_filter' >> beam.Filter(is_valid))\n",
    "\n",
    "      # Package raw training data and its metadata into a 'dataset'\n",
    "      raw_dataset = (raw_data, raw_data_metadata)\n",
    "      \n",
    "      # Using the preprocessing function `preprocess_tft`, preprocess the training data\n",
    "      # and produce a transformed training dataset and a function to transform other data later\n",
    "      transformed_dataset, transform_fn = (\n",
    "          raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocess_tft))\n",
    "      \n",
    "      # Break out the transformed training data and its metadata\n",
    "      transformed_data, transformed_metadata = transformed_dataset\n",
    "      \n",
    "      # Write the transformed training data to files\n",
    "      _ = transformed_data | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'train'),\n",
    "          file_name_suffix='.gz',\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      \n",
    "      # Read in test data from BigQuery table and filter as we did with training data\n",
    "      raw_test_data = (p \n",
    "        | 'eval_read' >> beam.io.Read(beam.io.BigQuerySource(query=create_query(2, EVERY_N), use_standard_sql=True))\n",
    "        | 'eval_filter' >> beam.Filter(is_valid))\n",
    "      \n",
    "      # Package test data and metadata into a dataset\n",
    "      raw_test_dataset = (raw_test_data, raw_data_metadata)\n",
    "      \n",
    "      # Using the same transformation function that was calculated above, transform the test dataset\n",
    "      transformed_test_dataset = (\n",
    "          (raw_test_dataset, transform_fn) | beam_impl.TransformDataset())\n",
    "      \n",
    "      # Write the transformed test data to files\n",
    "      transformed_test_data, _ = transformed_test_dataset\n",
    "      _ = transformed_test_data | 'WriteTestData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'eval'),\n",
    "          file_name_suffix='.gz',\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      \n",
    "      # Write the transformation function to a file, as well\n",
    "      _ = (transform_fn\n",
    "           | 'WriteTransformFn' >>\n",
    "           transform_fn_io.WriteTransformFn(os.path.join(OUTPUT_DIR, 'metadata')))\n",
    "\n",
    "# Preprocess the training/test data\n",
    "preprocess(in_test_mode=False, EVERY_N=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2018-07-01T18:26:47Z  gs://eim-muse/analysis/hallelujah-effect/preproc_tft/\n",
      "      2068  2018-07-01T18:36:38Z  gs://eim-muse/analysis/hallelujah-effect/preproc_tft/eval-00000-of-00001.gz\n",
      "      3387  2018-07-01T18:34:16Z  gs://eim-muse/analysis/hallelujah-effect/preproc_tft/train-00000-of-00003.gz\n",
      "      5211  2018-07-01T18:34:16Z  gs://eim-muse/analysis/hallelujah-effect/preproc_tft/train-00001-of-00003.gz\n",
      "      3890  2018-07-01T18:34:16Z  gs://eim-muse/analysis/hallelujah-effect/preproc_tft/train-00002-of-00003.gz\n",
      "                                 gs://eim-muse/analysis/hallelujah-effect/preproc_tft/metadata/\n",
      "                                 gs://eim-muse/analysis/hallelujah-effect/preproc_tft/tmp/\n",
      "TOTAL: 5 objects, 14556 bytes (14.21 KiB)\n",
      "         0  2018-07-01T18:30:19Z  gs://eim-muse/analysis/hallelujah-effect/preproc_tft/metadata/\n",
      "                                 gs://eim-muse/analysis/hallelujah-effect/preproc_tft/metadata/rawdata_metadata/\n",
      "                                 gs://eim-muse/analysis/hallelujah-effect/preproc_tft/metadata/transform_fn/\n",
      "                                 gs://eim-muse/analysis/hallelujah-effect/preproc_tft/metadata/transformed_metadata/\n",
      "TOTAL: 1 objects, 0 bytes (0 B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 18:38:13.452320. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "# ls -l preproc_tft\n",
    "# ls preproc_tft/metadata\n",
    "gsutil ls -l gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/\n",
    "gsutil ls -l gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Train off preprocessed data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 18:38:44.367008. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'basic_features'\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 5, '_session_config': None, '_keep_checkpoint_max': 10, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1b8ce0fe50>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 5 secs (eval_spec.throttle_secs) or training is finished.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_transform/saved/input_fn_maker.py:557: read_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:833: read_keyed_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:542: read_keyed_batch_examples (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:550: queue_parsed_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-07-01 21:17:45.493670: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:loss = 49.981102, step = 1\n",
      "INFO:tensorflow:global_step/sec: 118.233\n",
      "INFO:tensorflow:loss = 34.41433, step = 101 (0.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.583\n",
      "INFO:tensorflow:loss = 37.34749, step = 201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.065\n",
      "INFO:tensorflow:loss = 31.932434, step = 301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.118\n",
      "INFO:tensorflow:loss = 41.46538, step = 401 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.742\n",
      "INFO:tensorflow:loss = 41.18877, step = 501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.113\n",
      "INFO:tensorflow:loss = 35.56585, step = 601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.807\n",
      "INFO:tensorflow:loss = 29.893665, step = 701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.206\n",
      "INFO:tensorflow:loss = 30.37802, step = 801 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.18\n",
      "INFO:tensorflow:loss = 31.392952, step = 901 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.915\n",
      "INFO:tensorflow:loss = 33.433228, step = 1001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.776\n",
      "INFO:tensorflow:loss = 31.01316, step = 1101 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.952\n",
      "INFO:tensorflow:loss = 31.165836, step = 1201 (0.234 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1268 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 28.284191.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-01-21:17:51\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-1268\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/5]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-01-21:17:52\n",
      "INFO:tensorflow:Saving dict for global step 1268: accuracy = 0.7352941, accuracy_baseline = 0.7352941, auc = 0.51111114, auc_precision_recall = 0.24982494, average_loss = 0.5944288, global_step = 1268, label/mean = 0.2647059, loss = 20.210579, precision = 0.0, prediction/mean = 0.23200516, recall = 0.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-1268\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/export/exporter/temp-1530479874/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-1268\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1269 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:loss = 27.884617, step = 1269\n",
      "INFO:tensorflow:global_step/sec: 114.955\n",
      "INFO:tensorflow:loss = 26.84722, step = 1369 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.324\n",
      "INFO:tensorflow:loss = 27.089233, step = 1469 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.206\n",
      "INFO:tensorflow:loss = 31.713236, step = 1569 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.714\n",
      "INFO:tensorflow:loss = 27.0625, step = 1669 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.772\n",
      "INFO:tensorflow:loss = 25.44444, step = 1769 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.695\n",
      "INFO:tensorflow:loss = 35.043488, step = 1869 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.004\n",
      "INFO:tensorflow:loss = 27.743849, step = 1969 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.447\n",
      "INFO:tensorflow:loss = 28.098484, step = 2069 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.952\n",
      "INFO:tensorflow:loss = 37.387962, step = 2169 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.666\n",
      "INFO:tensorflow:loss = 30.116539, step = 2269 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.513\n",
      "INFO:tensorflow:loss = 32.516964, step = 2369 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.581\n",
      "INFO:tensorflow:loss = 27.304028, step = 2469 (0.229 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2513 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 30.466803.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-01-21:18:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-2513\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/5]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-01-21:18:02\n",
      "INFO:tensorflow:Saving dict for global step 2513: accuracy = 0.7352941, accuracy_baseline = 0.7352941, auc = 0.52444446, auc_precision_recall = 0.25204143, average_loss = 0.60862094, global_step = 2513, label/mean = 0.2647059, loss = 20.693111, precision = 0.0, prediction/mean = 0.2157829, recall = 0.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-2513\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/export/exporter/temp-1530479883/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-2513\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2514 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:loss = 30.25401, step = 2514\n",
      "INFO:tensorflow:global_step/sec: 239.844\n",
      "INFO:tensorflow:loss = 30.921396, step = 2614 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.404\n",
      "INFO:tensorflow:loss = 30.076483, step = 2714 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.058\n",
      "INFO:tensorflow:loss = 33.30413, step = 2814 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.014\n",
      "INFO:tensorflow:loss = 32.270905, step = 2914 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.232\n",
      "INFO:tensorflow:loss = 28.075432, step = 3014 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.851\n",
      "INFO:tensorflow:loss = 28.615593, step = 3114 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.744\n",
      "INFO:tensorflow:loss = 27.543161, step = 3214 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.513\n",
      "INFO:tensorflow:loss = 28.713053, step = 3314 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.375\n",
      "INFO:tensorflow:loss = 25.857319, step = 3414 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.409\n",
      "INFO:tensorflow:loss = 26.99173, step = 3514 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.213\n",
      "INFO:tensorflow:loss = 28.326511, step = 3614 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.16\n",
      "INFO:tensorflow:loss = 23.771809, step = 3714 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.815\n",
      "INFO:tensorflow:loss = 29.891407, step = 3814 (0.218 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3826 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 25.847565.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-01-21:18:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-3826\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/5]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-01-21:18:12\n",
      "INFO:tensorflow:Saving dict for global step 3826: accuracy = 0.7352941, accuracy_baseline = 0.7352941, auc = 0.5111111, auc_precision_recall = 0.24733582, average_loss = 0.63612413, global_step = 3826, label/mean = 0.2647059, loss = 21.628222, precision = 0.0, prediction/mean = 0.19982946, recall = 0.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-3826\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/export/exporter/temp-1530479893/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-3826\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3827 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:loss = 23.805485, step = 3827\n",
      "INFO:tensorflow:global_step/sec: 124.719\n",
      "INFO:tensorflow:loss = 24.774826, step = 3927 (0.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.539\n",
      "INFO:tensorflow:loss = 27.249445, step = 4027 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.192\n",
      "INFO:tensorflow:loss = 27.421444, step = 4127 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.38\n",
      "INFO:tensorflow:loss = 25.500666, step = 4227 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.346\n",
      "INFO:tensorflow:loss = 28.21828, step = 4327 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.712\n",
      "INFO:tensorflow:loss = 24.753603, step = 4427 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.995\n",
      "INFO:tensorflow:loss = 25.654415, step = 4527 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.066\n",
      "INFO:tensorflow:loss = 21.669392, step = 4627 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.741\n",
      "INFO:tensorflow:loss = 23.077377, step = 4727 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.987\n",
      "INFO:tensorflow:loss = 26.267872, step = 4827 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.969\n",
      "INFO:tensorflow:loss = 28.38003, step = 4927 (0.229 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 24.252825.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-01-21:18:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/5]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-01-21:18:21\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7352941, accuracy_baseline = 0.7352941, auc = 0.51555556, auc_precision_recall = 0.249648, average_loss = 0.6567924, global_step = 5000, label/mean = 0.2647059, loss = 22.330942, precision = 0.0, prediction/mean = 0.19283599, recall = 0.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/models/basic_features/export/exporter/temp-1530479902/saved_model.pb\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 21:17:41.107202. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf ${PWD}/models/${MODEL_NAME}\n",
    "export PYTHONPATH=${PYTHONPATH}:$PWD/taxifare_tft\n",
    "python -m trainer.task \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/eval*\"  \\\n",
    "   --train_batch_size=64 \\\n",
    "   --output_dir=${PWD}/models/${MODEL_NAME} \\\n",
    "   --train_steps=5000 --eval_steps=5 --job-dir=/tmp \\\n",
    "   --metadata_path=gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata\n",
    "  \n",
    "# OUTDIR=gs://${BUCKET}/analysis/hallelujah-effect/models/${MODEL_NAME}\n",
    "# JOBNAME=hallelujah_effect$(date -u +%y%m%d_%H%M%S)\n",
    "# echo $OUTDIR $REGION $JOBNAME\n",
    "# gsutil -m rm -rf $OUTDIR\n",
    "# gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "#    --region=$REGION \\\n",
    "#    --package-path=${PWD}/taxifare_tft/trainer \\\n",
    "#    --module-name=trainer.task \\\n",
    "#    --job-dir=$OUTDIR \\\n",
    "#    --scale-tier=STANDARD_1 \\\n",
    "#    --runtime-version=1.4 \\\n",
    "#    -- \\\n",
    "#    --train_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/train*\" \\\n",
    "#    --eval_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/eval*\" \\\n",
    "#    --output_dir=$OUTDIR \\\n",
    "#    --train_steps=50000 \\\n",
    "#    --train_batch_size=64 \\\n",
    "#    --eval_steps=1 \\\n",
    "#    --metadata_path=gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 32489. Click <a href=\"/_proxy/49425/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "32489"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 22:01:58.348723. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://eim-muse/analysis/hallelujah-effect/models/basic_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 22:01:08.716942. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "TensorBoard.stop(27995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf ${PWD}/models/local-ml\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/taxifare_tft/trainer \\\n",
    "   --job-dir=${PWD}/models/local-ml \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/eval*\" \\\n",
    "   --train_steps=1000 \\\n",
    "   --train_batch_size=10 \\\n",
    "   --eval_steps=100 \\\n",
    "   --output_dir=${PWD}/models/local-ml \\\n",
    "   --metadata_path=gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://eim-muse/analysis/hallelujah-effect/models/basic_features us-central1 hallelujah_effect180701_222634\n",
      "jobId: hallelujah_effect180701_222634\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/checkpoint#1530482826655749...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/#1530482822823850...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/eval/#1530482769121873...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/eval/events.out.tfevents.1530482769.cmle-training-master-63f7af02fa-0-bpkkf#1530482830698929...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/events.out.tfevents.1530482730.cmle-training-master-63f7af02fa-0-bpkkf#1530482839822087...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/#1530482773392455...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/#1530482773698877...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482771/#1530482779443119...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482771/saved_model.pb#1530482779765139...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482771/variables/#1530482780065107...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482771/variables/variables.data-00000-of-00001#1530482780390066...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482771/variables/variables.index#1530482780727361...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482792/#1530482799225252...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482792/saved_model.pb#1530482799530602...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482792/variables/#1530482799829387...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482792/variables/variables.data-00000-of-00001#1530482800091167...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482792/variables/variables.index#1530482800496670...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482812/#1530482818999021...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482812/saved_model.pb#1530482819284231...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482812/variables/#1530482819631997...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482812/variables/variables.data-00000-of-00001#1530482819949049...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482812/variables/variables.index#1530482820291709...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482831/#1530482838066133...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482831/saved_model.pb#1530482838352374...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482831/variables/#1530482838671727...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482831/variables/variables.data-00000-of-00001#1530482838929113...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/export/exporter/1530482831/variables/variables.index#1530482839232531...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-1083.data-00000-of-00003#1530482762847321...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/graph.pbtxt#1530482757490311...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-1083.data-00001-of-00003#1530482762335492...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-1083.data-00002-of-00003#1530482761814638...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-1083.index#1530482763350861...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-1083.meta#1530482765697548...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-22324.data-00000-of-00003#1530482785810306...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-22324.data-00001-of-00003#1530482785325828...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-22324.data-00002-of-00003#1530482784856660...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-22324.index#1530482786234699...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-22324.meta#1530482788636541...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-41019.data-00000-of-00003#1530482805330989...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-41019.data-00001-of-00003#1530482804883379...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-41019.data-00002-of-00003#1530482804450389...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-41019.index#1530482805745033...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-41019.meta#1530482808221199...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-50004.data-00000-of-00003#1530482824907787...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-50004.data-00001-of-00003#1530482824441967...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-50004.data-00002-of-00003#1530482824020148...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-50004.index#1530482825403769...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/packages/36a20c9ca847620c6e68d1e38ca0e5183c6492b7bdc8e5ae1a257e14aaba95e4/trainer-0.1.tar.gz#1530482493181137...\n",
      "Removing gs://eim-muse/analysis/hallelujah-effect/models/basic_features/model.ckpt-50004.meta#1530482827572800...\n",
      "/ [49/49 objects] 100% Done                                                     \n",
      "Operation completed over 49 objects.                                             \n",
      "Job [hallelujah_effect180701_222634] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hallelujah_effect180701_222634\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hallelujah_effect180701_222634\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 22:26:34.560548. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/analysis/hallelujah-effect/models/${MODEL_NAME}\n",
    "JOBNAME=hallelujah_effect$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --package-path=${PWD}/taxifare_tft/trainer \\\n",
    "   --module-name=trainer.task \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --scale-tier=STANDARD_1 \\\n",
    "   --runtime-version=1.4 \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/eval*\" \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=500000 \\\n",
    "   --train_batch_size=128 \\\n",
    "   --eval_steps=1 \\\n",
    "   --metadata_path=gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata/\n",
    "\n",
    "#    --config=hyperparam.yaml\n",
    "# --staging-bucket=gs://eim-muse-staging \\\n",
    "\n",
    "# export PYTHONPATH=${PYTHONPATH}:$PWD/taxifare_tft\n",
    "# python -m trainer.task \\\n",
    "#    --train_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/train*\" \\\n",
    "#    --eval_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/eval*\"  \\\n",
    "#    --train_batch_size=10 \\\n",
    "#    --output_dir=\"gs://${BUCKET}/analysis/hallelujah-effect/models/hallelujah-effect_trained\" \\\n",
    "#    --train_steps=5000 --eval_steps=1 --job-dir=/tmp \\\n",
    "#    --metadata_path=gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%writefile /tmp/test.json\n",
    "{\"age\":\"29.0\",\"activity\":3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "model_dir=$(ls $PWD/hallelujah-effect_trained/export/exporter/)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=./hallelujah-effect_trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# To Do\n",
    "\n",
    "- LASSO to identify important features\n",
    "- Hyperparameter search\n",
    "- More plots and statistics from the dataset with which I'm working here\n",
    "- Bring in rows with missing values\n",
    "- Feature engineering (physiological signals, MIR, feature crosses, variable-width binning)\n",
    "- Include signals with good quality only in reaction range\n",
    "- Customize estimator to add additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://eim-muse/analysis/hallelujah-effect/models/basic_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 20:34:08.418586. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "print('gs://{}/analysis/hallelujah-effect/models/{}'.format(BUCKET, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
