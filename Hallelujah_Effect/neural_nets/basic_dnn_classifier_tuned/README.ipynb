{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hyperparameters available for tuning:\n",
    "\n",
    "- `train_batch_size`\n",
    "- `train_steps`\n",
    "- `nbuckets` (currently unused)\n",
    "- `hidden_units`\n",
    "- `learning_rate`\n",
    "- `beta1`\n",
    "- `beta2`\n",
    "- `dropout`\n",
    "- `activation_function`\n",
    "\n",
    "This set of notebooks trains a deep classifier (`DNNClassifier`) on the following features:\n",
    "\n",
    "- activity\n",
    "- age\n",
    "- artistic\n",
    "- concentration\n",
    "- engagement\n",
    "- familiarity\n",
    "- fault\n",
    "- imagination\n",
    "- lazy\n",
    "- like_dislike\n",
    "- musical_expertise\n",
    "- nervous\n",
    "- outgoing\n",
    "- positivity\n",
    "- reserved\n",
    "- stress\n",
    "- tension\n",
    "- thorough\n",
    "- trusting\n",
    "- hallelujah_reaction\n",
    "- hearing_impairments\n",
    "- music_pref_classical\n",
    "- music_pref_dance\n",
    "- music_pref_folk\n",
    "- music_pref_hiphop\n",
    "- music_pref_jazz\n",
    "- music_pref_none\n",
    "- music_pref_pop\n",
    "- music_pref_rock\n",
    "- music_pref_traditional_irish\n",
    "- music_pref_world\n",
    "- language\n",
    "- location\n",
    "- nationality\n",
    "- sex\n",
    "\n",
    "The following values for configuring the `DNNClassifer` were used:\n",
    "\n",
    "    hidden_units=,\n",
    "    feature_columns,\n",
    "    model_dir=None,\n",
    "    n_classes=2,\n",
    "    weight_column=None,\n",
    "    label_vocabulary=None,\n",
    "    optimizer='Adagrad',\n",
    "    activation_fn=tf.nn.relu,\n",
    "    dropout=None,\n",
    "    input_layer_partitioner=None,\n",
    "    config=None,\n",
    "    warm_start_from=None,\n",
    "    loss_reduction=losses.Reduction.SUM\n",
    "\n",
    "Batch training was performed (n = 303) for 2,500,000 epochs. Evaluation results from this training were:\n",
    "\n",
    "- Accuracy = 0.55737704\n",
    "- Accuracy baseline = 0.6721312\n",
    "- AUC = 0.4573171\n",
    "- AUC-PR = 0.30257925\n",
    "- Average loss = 13.65598\n",
    "- F1 score = 0.12903225\n",
    "- False negatives = 18.0\n",
    "- False positives = 9.0\n",
    "- Label/mean = 0.32786885\n",
    "- Loss = 833.0148\n",
    "- Precision = 0.18181819\n",
    "- Prediction/mean = 0.190581\n",
    "- Recall = 0.1\n",
    "- True negatives = 32.0\n",
    "- True positives = 2.0\n",
    "\n",
    "The model is located at `gs://eim-muse/analysis/hallelujah-effect/models/basic_features_hyperparameter_tuning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Abridged results of 211 hyperparameter tuning trials:\n",
    "\n",
    "```\n",
    "\t\n",
    "{\n",
    "  \"completedTrialCount\": \"211\",\n",
    "  \"trials\": [\n",
    "    {\n",
    "      \"trialId\": \"2\",\n",
    "      \"hyperparameters\": {\n",
    "        \"activation_function\": \"relu\",\n",
    "        \"learning_rate\": \"0.5\",\n",
    "        \"dropout\": \"0.5\",\n",
    "        \"hidden_units\": \"16 8 4\",\n",
    "        \"train_steps\": \"500\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"501\",\n",
    "        \"objectiveValue\": 0.663934409618\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"trialId\": \"3\",\n",
    "      \"hyperparameters\": {\n",
    "        \"activation_function\": \"relu\",\n",
    "        \"learning_rate\": \"0.5\",\n",
    "        \"dropout\": \"0.25\",\n",
    "        \"hidden_units\": \"64 64 64 8\",\n",
    "        \"train_steps\": \"20000\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"20005\",\n",
    "        \"objectiveValue\": 0.663934409618\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"trialId\": \"57\",\n",
    "      \"hyperparameters\": {\n",
    "        \"train_steps\": \"10000\",\n",
    "        \"activation_function\": \"relu\",\n",
    "        \"learning_rate\": \"0.1\",\n",
    "        \"dropout\": \"0\",\n",
    "        \"hidden_units\": \"128 32 4\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"50006\",\n",
    "        \"objectiveValue\": 0.560208499432\n",
    "      }\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"consumedMLUnits\": 208.23,\n",
    "  \"isHyperparameterTuningJob\": true\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plots of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_function</th>\n",
       "      <th>dropout</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>hidden_units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.663934</td>\n",
       "      <td>16 8 4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.663934</td>\n",
       "      <td>64 64 64 8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.560208</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.441225</td>\n",
       "      <td>64 64 64 8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428006</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382998</td>\n",
       "      <td>64 64 64 8</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>elu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.368522</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>128 32 4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_function dropout  f1_score hidden_units learning_rate  \\\n",
       "0                 relu     0.5  0.663934       16 8 4           0.5   \n",
       "1                 relu    0.25  0.663934   64 64 64 8           0.5   \n",
       "2                 relu       0  0.560208     128 32 4           0.1   \n",
       "3                 relu    0.75  0.560208     128 32 4          0.25   \n",
       "4                 relu    0.75  0.560208     128 32 4          0.01   \n",
       "5                 relu    0.75  0.560208     128 32 4          0.01   \n",
       "6                 relu    0.75  0.560208     128 32 4          0.25   \n",
       "7                 relu     0.5  0.560208     128 32 4         0.001   \n",
       "8                 relu       0  0.560208     128 32 4           0.1   \n",
       "9                 relu    0.75  0.560208     128 32 4          0.01   \n",
       "10                relu    0.25  0.560208     128 32 4         0.001   \n",
       "11                relu    0.25  0.560208     128 32 4           0.1   \n",
       "12                relu     0.5  0.560208     128 32 4           0.1   \n",
       "13                relu    0.75  0.560208     128 32 4           0.5   \n",
       "14                relu     0.5  0.560208     128 32 4           0.1   \n",
       "15                relu    0.25  0.560208     128 32 4           0.1   \n",
       "16                relu    0.75  0.560208     128 32 4          0.01   \n",
       "17                relu     0.5  0.560208     128 32 4           0.5   \n",
       "18                relu     0.5  0.560208     128 32 4           0.1   \n",
       "19                relu    0.75  0.560208     128 32 4           0.5   \n",
       "20          leaky_relu    0.75  0.441225   64 64 64 8          0.25   \n",
       "21                 elu    0.75  0.428006     128 32 4          0.01   \n",
       "22                 elu    0.25  0.428006     128 32 4          0.01   \n",
       "23                 elu    0.75  0.428006     128 32 4          0.25   \n",
       "24                 elu    0.25  0.428006     128 32 4          0.01   \n",
       "25                 elu    0.75  0.428006     128 32 4          0.25   \n",
       "26                 elu       0  0.428006     128 32 4           0.1   \n",
       "27                 elu     0.5  0.428006     128 32 4          0.01   \n",
       "28                 elu    0.25  0.428006     128 32 4          0.01   \n",
       "29                 elu       0  0.428006     128 32 4           0.1   \n",
       "30                 elu    0.75  0.428006     128 32 4           0.1   \n",
       "31                 elu       0  0.428006     128 32 4          0.01   \n",
       "32                 elu    0.75  0.428006     128 32 4          0.01   \n",
       "33                 elu     0.5  0.428006     128 32 4           0.5   \n",
       "34                 elu     0.5  0.428006     128 32 4         0.001   \n",
       "35                 elu     0.5  0.428006     128 32 4          0.01   \n",
       "36                 elu    0.25  0.428006     128 32 4          0.25   \n",
       "37                 elu    0.25  0.428006     128 32 4          0.01   \n",
       "38                 elu    0.25  0.428006     128 32 4         0.001   \n",
       "39                 elu    0.25  0.428006     128 32 4          0.01   \n",
       "40                 elu    0.25  0.428006     128 32 4           0.5   \n",
       "41                 elu    0.75  0.428006     128 32 4          0.25   \n",
       "42                 elu       0  0.382998   64 64 64 8         0.001   \n",
       "43                 elu    0.25  0.368522     128 32 4          0.01   \n",
       "44          leaky_relu    0.25  0.292824     128 32 4          0.25   \n",
       "45          leaky_relu       0  0.292824     128 32 4         0.001   \n",
       "46          leaky_relu     0.5  0.292824     128 32 4           0.1   \n",
       "47          leaky_relu     0.5  0.292824     128 32 4          0.01   \n",
       "48          leaky_relu    0.25  0.292824     128 32 4          0.01   \n",
       "49          leaky_relu    0.25  0.292824     128 32 4           0.1   \n",
       "50          leaky_relu       0  0.292824     128 32 4         0.001   \n",
       "51          leaky_relu    0.75  0.292824     128 32 4           0.5   \n",
       "52          leaky_relu       0  0.292824     128 32 4          0.25   \n",
       "53          leaky_relu       0  0.292824     128 32 4         0.001   \n",
       "54          leaky_relu     0.5  0.292824     128 32 4          0.01   \n",
       "55          leaky_relu    0.75  0.292824     128 32 4         0.001   \n",
       "56          leaky_relu    0.25  0.292824     128 32 4           0.1   \n",
       "57          leaky_relu    0.25  0.292824     128 32 4           0.1   \n",
       "\n",
       "   train_steps  \n",
       "0          500  \n",
       "1        20000  \n",
       "2        10000  \n",
       "3        20000  \n",
       "4         5000  \n",
       "5         5000  \n",
       "6         5000  \n",
       "7        10000  \n",
       "8        10000  \n",
       "9         5000  \n",
       "10         500  \n",
       "11       30000  \n",
       "12       30000  \n",
       "13       50000  \n",
       "14       20000  \n",
       "15       10000  \n",
       "16        5000  \n",
       "17         500  \n",
       "18       10000  \n",
       "19       10000  \n",
       "20        5000  \n",
       "21       50000  \n",
       "22       20000  \n",
       "23       50000  \n",
       "24       20000  \n",
       "25       50000  \n",
       "26       30000  \n",
       "27         500  \n",
       "28       20000  \n",
       "29       30000  \n",
       "30       30000  \n",
       "31        5000  \n",
       "32       50000  \n",
       "33        5000  \n",
       "34       20000  \n",
       "35         500  \n",
       "36       20000  \n",
       "37       20000  \n",
       "38         500  \n",
       "39       30000  \n",
       "40       50000  \n",
       "41       50000  \n",
       "42       20000  \n",
       "43       20000  \n",
       "44       50000  \n",
       "45         500  \n",
       "46       20000  \n",
       "47       30000  \n",
       "48       30000  \n",
       "49       20000  \n",
       "50         500  \n",
       "51        5000  \n",
       "52       10000  \n",
       "53       30000  \n",
       "54        5000  \n",
       "55       10000  \n",
       "56        5000  \n",
       "57       20000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('tuning_results.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[~np.isnan(df[\"f1_score\"])]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
