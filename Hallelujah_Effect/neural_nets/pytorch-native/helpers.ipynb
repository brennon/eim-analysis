{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(dataloader, model, optimizer, criterion, init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    from torch import Tensor\n",
    "    import math\n",
    "    \n",
    "    # Save current state_dict of model\n",
    "    original_state = model.state_dict\n",
    "    \n",
    "    num = len(dataloader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    opt.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in dataloader:\n",
    "        batch_num += 1\n",
    "        #As before, get the loss for this mini-batch of inputs/outputs\n",
    "        x_cats, x_conts, y = data\n",
    "        x_cats, x_conts, y = torch.LongTensor(x_cats), torch.FloatTensor(x_conts), torch.FloatTensor(y)\n",
    "        x_cats.requires_grad, x_conts.requires_grad = False, False\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_cats, x_conts)\n",
    "        loss = criterion(outputs, y)\n",
    "        #Compute the smoothed loss\n",
    "        print(loss)\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.data\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "            print('best loss: {}'.format(best_loss))\n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "#         log_lrs.append(lr)\n",
    "        #Do the SGD step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "    # Reset model state_dict\n",
    "    model.state_dict = original_state\n",
    "    \n",
    "    return log_lrs, losses\n",
    "\n",
    "lrs, losses = find_lr(model_data.trn_dl, emb_model, opt, crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
