{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# \"Hallelujah Effect\" Analysis\n",
    "\n",
    "This notebook models the \"Hallelujah Effect\" in terms of all basic features available in the dataset for those subjects that listened to the song and had an EDA quality >80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "pip uninstall -y google-cloud-dataflow\n",
    "pip install --upgrade --force tensorflow_transform==0.6.0 apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Restart the kernel</b> after you do a pip install (click on the <b>Reset</b> button in Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-airflow==1.9.0\n",
      "apache-beam==2.5.0\n",
      "tensorflow==1.8.0\n",
      "tensorflow-transform==0.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "pip freeze | grep -e 'flow\\|beam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set bucket, project, and region\n",
    "BUCKET = 'eim-muse'\n",
    "PROJECT = 'eim-muse'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Retrieve and Subset Datasource\n",
    "\n",
    "Get data from BigQuery but defer filtering, etc. to Beam. Data in BigQuery has been pre-processed with Dataprep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1=train 2=valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT *\n",
    "FROM\n",
    "  `eim-muse.hallelujah_effect.full_hallelujah_trials_cleaned`\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} WHERE MOD(FARM_FINGERPRINT(id), 10) < 7\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} WHERE MOD(FARM_FINGERPRINT(id), 10) >= 7\".format(base_query)\n",
    "  else:\n",
    "      query = \"{0} WHERE MOD(FARM_FINGERPRINT(id), {1}) = {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(1, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>concentration</th>\n",
       "      <th>musical_expertise</th>\n",
       "      <th>artistic</th>\n",
       "      <th>fault</th>\n",
       "      <th>imagination</th>\n",
       "      <th>lazy</th>\n",
       "      <th>nervous</th>\n",
       "      <th>outgoing</th>\n",
       "      <th>reserved</th>\n",
       "      <th>...</th>\n",
       "      <th>music_pref_none</th>\n",
       "      <th>music_pref_hiphop</th>\n",
       "      <th>music_pref_dance</th>\n",
       "      <th>music_pref_world</th>\n",
       "      <th>music_pref_rock</th>\n",
       "      <th>music_pref_pop</th>\n",
       "      <th>music_pref_classical</th>\n",
       "      <th>music_pref_jazz</th>\n",
       "      <th>music_pref_folk</th>\n",
       "      <th>music_pref_traditional_irish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.726073</td>\n",
       "      <td>3.993500</td>\n",
       "      <td>2.547224</td>\n",
       "      <td>2.344099</td>\n",
       "      <td>3.175612</td>\n",
       "      <td>3.852643</td>\n",
       "      <td>3.690403</td>\n",
       "      <td>3.629726</td>\n",
       "      <td>3.213016</td>\n",
       "      <td>3.145503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.132013</td>\n",
       "      <td>0.432343</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.059406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.931034</td>\n",
       "      <td>0.795258</td>\n",
       "      <td>1.009324</td>\n",
       "      <td>0.988361</td>\n",
       "      <td>0.891464</td>\n",
       "      <td>0.821620</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>0.875898</td>\n",
       "      <td>0.961299</td>\n",
       "      <td>0.891699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081110</td>\n",
       "      <td>0.346115</td>\n",
       "      <td>0.391454</td>\n",
       "      <td>0.339065</td>\n",
       "      <td>0.496221</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>0.461983</td>\n",
       "      <td>0.377671</td>\n",
       "      <td>0.285372</td>\n",
       "      <td>0.236774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.991266</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.824561</td>\n",
       "      <td>3.659389</td>\n",
       "      <td>3.596491</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.991266</td>\n",
       "      <td>2.529880</td>\n",
       "      <td>2.353712</td>\n",
       "      <td>3.144737</td>\n",
       "      <td>3.824561</td>\n",
       "      <td>3.659389</td>\n",
       "      <td>3.596491</td>\n",
       "      <td>3.228070</td>\n",
       "      <td>3.117904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.353712</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  concentration  musical_expertise    artistic       fault  \\\n",
       "count  303.000000     303.000000         303.000000  303.000000  303.000000   \n",
       "mean    24.726073       3.993500           2.547224    2.344099    3.175612   \n",
       "std     13.931034       0.795258           1.009324    0.988361    0.891464   \n",
       "min      1.000000       1.000000           1.000000    1.000000    1.000000   \n",
       "25%     16.000000       3.991266           2.000000    2.000000    3.000000   \n",
       "50%     21.000000       3.991266           2.529880    2.353712    3.144737   \n",
       "75%     31.000000       4.000000           3.000000    2.353712    4.000000   \n",
       "max    121.000000       5.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "       imagination        lazy     nervous    outgoing    reserved  \\\n",
       "count   303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean      3.852643    3.690403    3.629726    3.213016    3.145503   \n",
       "std       0.821620    0.905895    0.875898    0.961299    0.891699   \n",
       "min       1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%       3.824561    3.659389    3.596491    3.000000    3.000000   \n",
       "50%       3.824561    3.659389    3.596491    3.228070    3.117904   \n",
       "75%       4.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "max       5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "                   ...               music_pref_none  music_pref_hiphop  \\\n",
       "count              ...                    303.000000         303.000000   \n",
       "mean               ...                      0.006601           0.138614   \n",
       "std                ...                      0.081110           0.346115   \n",
       "min                ...                      0.000000           0.000000   \n",
       "25%                ...                      0.000000           0.000000   \n",
       "50%                ...                      0.000000           0.000000   \n",
       "75%                ...                      0.000000           0.000000   \n",
       "max                ...                      1.000000           1.000000   \n",
       "\n",
       "       music_pref_dance  music_pref_world  music_pref_rock  music_pref_pop  \\\n",
       "count        303.000000        303.000000       303.000000      303.000000   \n",
       "mean           0.188119          0.132013         0.432343        0.673267   \n",
       "std            0.391454          0.339065         0.496221        0.469794   \n",
       "min            0.000000          0.000000         0.000000        0.000000   \n",
       "25%            0.000000          0.000000         0.000000        0.000000   \n",
       "50%            0.000000          0.000000         0.000000        1.000000   \n",
       "75%            0.000000          0.000000         1.000000        1.000000   \n",
       "max            1.000000          1.000000         1.000000        1.000000   \n",
       "\n",
       "       music_pref_classical  music_pref_jazz  music_pref_folk  \\\n",
       "count            303.000000       303.000000       303.000000   \n",
       "mean               0.306931         0.171617         0.089109   \n",
       "std                0.461983         0.377671         0.285372   \n",
       "min                0.000000         0.000000         0.000000   \n",
       "25%                0.000000         0.000000         0.000000   \n",
       "50%                0.000000         0.000000         0.000000   \n",
       "75%                1.000000         0.000000         0.000000   \n",
       "max                1.000000         1.000000         1.000000   \n",
       "\n",
       "       music_pref_traditional_irish  \n",
       "count                    303.000000  \n",
       "mean                       0.059406  \n",
       "std                        0.236774  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        0.000000  \n",
       "75%                        0.000000  \n",
       "max                        1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = bq.Query(query).execute().result().to_dataframe()\n",
    "df_valid.head()\n",
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 training examples / 61 evaluation examples\n"
     ]
    }
   ],
   "source": [
    "train_query = create_query(1, None)\n",
    "train_n = len(list(bq.Query(train_query).execute().result()))\n",
    "\n",
    "eval_query = create_query(2, None)\n",
    "eval_n = len(list(bq.Query(eval_query).execute().result()))\n",
    "\n",
    "os.environ['TRAIN_N'] = str(train_n)\n",
    "os.environ['EVAL_N'] = str(eval_n)\n",
    "\n",
    "print('{} training examples / {} evaluation examples'.format(train_n, eval_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'age', u'concentration', u'hearing_impairments',\n",
       "       u'musical_expertise', u'nationality', u'artistic', u'fault',\n",
       "       u'imagination', u'lazy', u'nervous', u'outgoing', u'reserved',\n",
       "       u'stress', u'thorough', u'trusting', u'activity', u'engagement',\n",
       "       u'familiarity', u'like_dislike', u'positivity', u'tension', u'sex',\n",
       "       u'hallelujah_reaction', u'location', u'language', u'music_pref_none',\n",
       "       u'music_pref_hiphop', u'music_pref_dance', u'music_pref_world',\n",
       "       u'music_pref_rock', u'music_pref_pop', u'music_pref_classical',\n",
       "       u'music_pref_jazz', u'music_pref_folk',\n",
       "       u'music_pref_traditional_irish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create ML dataset using tf.transform and Dataflow\n",
    "\n",
    "Let's use Cloud Dataflow to read in the BigQuery data and write it out as CSV files. Along the way, let's use tf.transform to do scaling and transforming. Using tf.transform allows us to save the metadata to ensure that the appropriate transformations get carried out during prediction as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%writefile requirements.txt\n",
    "tensorflow-transform==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching local job ... hang on\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/19bb5413bd4b4b0f8e36621e3922af0c/saved_model.pb\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/b65580123bf9446cb74310cb4a9f1128/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/apache_beam/runners/direct/direct_runner.py:342: DeprecationWarning: options is deprecated since First stable release.. References to <pipeline>.options will not be supported\n",
      "  pipeline.replace_all(_get_transform_overrides(pipeline.options))\n",
      "WARNING:root:Dataset eim-muse:temp_dataset_5a0af3dc468743a38e880d08169800c5 does not exist so we will create it as temporary with location=None\n",
      "WARNING:root:Dataset eim-muse:temp_dataset_879b26de5073457cb0f8af39f9ec4a87 does not exist so we will create it as temporary with location=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/9ca1a4d8d57945c898e9ad464331262c/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./preproc_tft/tmp/tftransform_tmp/9ca1a4d8d57945c898e9ad464331262c/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-10 01:20:05.224311. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "\n",
    "def is_valid(inputs):\n",
    "    try:\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "float_features = [\n",
    "    'activity',\n",
    "    'age',\n",
    "    'artistic',\n",
    "    'concentration',\n",
    "    'engagement',\n",
    "    'familiarity',\n",
    "    'fault',\n",
    "    'imagination',\n",
    "    'lazy',\n",
    "    'like_dislike',\n",
    "    'musical_expertise',\n",
    "    'nervous',\n",
    "    'outgoing',\n",
    "    'positivity',\n",
    "    'reserved',\n",
    "    'stress',\n",
    "    'tension',\n",
    "    'thorough',\n",
    "    'trusting'\n",
    "]\n",
    "\n",
    "boolean_features = [\n",
    "    'hallelujah_reaction',\n",
    "    'hearing_impairments',\n",
    "    'music_pref_classical',\n",
    "    'music_pref_dance',\n",
    "    'music_pref_folk',\n",
    "    'music_pref_hiphop',\n",
    "    'music_pref_jazz',\n",
    "    'music_pref_none',\n",
    "    'music_pref_pop',\n",
    "    'music_pref_rock',\n",
    "    'music_pref_traditional_irish',\n",
    "    'music_pref_world'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'language',\n",
    "    'location',\n",
    "    'nationality',\n",
    "    'sex'\n",
    "]\n",
    "\n",
    "def preprocess_tft(inputs):\n",
    "    import datetime\n",
    "    result = {}\n",
    "    \n",
    "    for feature in float_features:\n",
    "        result[feature] = tft.scale_to_0_1(inputs[feature])\n",
    "    \n",
    "    for feature in boolean_features:\n",
    "        result[feature] = tf.cast(inputs[feature], tf.int64)\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        result[feature] = tf.identity(inputs[feature])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def preprocess(in_test_mode, EVERY_N=None):\n",
    "  import os\n",
    "  import os.path\n",
    "  import tempfile\n",
    "  from apache_beam.io import tfrecordio\n",
    "  from tensorflow_transform.coders import example_proto_coder\n",
    "  from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "  from tensorflow_transform.tf_metadata import dataset_schema\n",
    "  from tensorflow_transform.beam import tft_beam_io\n",
    "  from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "\n",
    "  job_name = 'hallelujah-effect-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')    \n",
    "  if in_test_mode:\n",
    "    import shutil\n",
    "    print 'Launching local job ... hang on'\n",
    "    OUTPUT_DIR = './preproc_tft'\n",
    "    shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "    \n",
    "  else:\n",
    "    print 'Launching Dataflow job {} ... hang on'.format(job_name)\n",
    "    OUTPUT_DIR = 'gs://{0}/analysis/hallelujah-effect/preproc_tft/'.format(BUCKET)\n",
    "    import subprocess\n",
    "    subprocess.call('gsutil rm -r {}'.format(OUTPUT_DIR).split())\n",
    "  \n",
    "  # Configure Beam pipeline options\n",
    "  options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': job_name,\n",
    "    'project': PROJECT,\n",
    "    'max_num_workers': 24,\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True,\n",
    "    'requirements_file': 'requirements.txt'\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "  if in_test_mode:\n",
    "    RUNNER = 'DirectRunner'\n",
    "  else:\n",
    "    RUNNER = 'DataflowRunner'\n",
    "\n",
    "  # Setup metadata\n",
    "  raw_data_schema = {\n",
    "    colname : dataset_schema.ColumnSchema(tf.string, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in categorical_features\n",
    "  }\n",
    "  raw_data_schema.update({\n",
    "      colname : dataset_schema.ColumnSchema(tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in float_features\n",
    "    })\n",
    "  raw_data_schema.update({\n",
    "      colname : dataset_schema.ColumnSchema(tf.int64, [], dataset_schema.FixedColumnRepresentation())\n",
    "                   for colname in boolean_features\n",
    "    })\n",
    "  raw_data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.Schema(raw_data_schema))\n",
    "  \n",
    "  # run Beam  \n",
    "  with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "    with beam_impl.Context(temp_dir=os.path.join(OUTPUT_DIR, 'tmp')):\n",
    "      \n",
    "      # Write the raw data metadata to disk\n",
    "      # Without the overloaded operators: p.apply(tft_beam_io.WriteMetadata(os.path.join(OUTPUT_DIR, 'metadata/rawdata_metadata'), raw_data_metadata)\n",
    "      _ = (raw_data_metadata\n",
    "        | 'WriteInputMetadata' >> tft_beam_io.WriteMetadata(\n",
    "            os.path.join(OUTPUT_DIR, 'metadata/rawdata_metadata'),\n",
    "            pipeline=p))\n",
    "           \n",
    "      # Analyze and transform training data\n",
    "      this_query = create_query(1, EVERY_N)\n",
    "      \n",
    "      # Read in training data from BigQuery table\n",
    "      raw_data = (p\n",
    "        # Get raw training data from BigQuery\n",
    "        | 'train_read' >> beam.io.Read(beam.io.BigQuerySource(query=this_query, use_standard_sql=True))\n",
    "        # Use our is_valid function to only retain valid examples from training data\n",
    "        | 'train_filter' >> beam.Filter(is_valid))\n",
    "\n",
    "      # Package raw training data and its metadata into a 'dataset'\n",
    "      raw_dataset = (raw_data, raw_data_metadata)\n",
    "      \n",
    "      # Using the preprocessing function `preprocess_tft`, preprocess the training data\n",
    "      # and produce a transformed training dataset and a function to transform other data later\n",
    "      transformed_dataset, transform_fn = (\n",
    "          raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocess_tft))\n",
    "      \n",
    "      # Break out the transformed training data and its metadata\n",
    "      transformed_data, transformed_metadata = transformed_dataset\n",
    "      \n",
    "      # Write the transformed training data to files\n",
    "      _ = transformed_data | 'WriteTrainData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'train'),\n",
    "          file_name_suffix='.gz',\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      \n",
    "      # Read in test data from BigQuery table and filter as we did with training data\n",
    "      raw_test_data = (p \n",
    "        | 'eval_read' >> beam.io.Read(beam.io.BigQuerySource(query=create_query(2, EVERY_N), use_standard_sql=True))\n",
    "        | 'eval_filter' >> beam.Filter(is_valid))\n",
    "      \n",
    "      # Package test data and metadata into a dataset\n",
    "      raw_test_dataset = (raw_test_data, raw_data_metadata)\n",
    "      \n",
    "      # Using the same transformation function that was calculated above, transform the test dataset\n",
    "      transformed_test_dataset = (\n",
    "          (raw_test_dataset, transform_fn) | beam_impl.TransformDataset())\n",
    "      \n",
    "      # Write the transformed test data to files\n",
    "      transformed_test_data, _ = transformed_test_dataset\n",
    "      _ = transformed_test_data | 'WriteTestData' >> tfrecordio.WriteToTFRecord(\n",
    "          os.path.join(OUTPUT_DIR, 'eval'),\n",
    "          file_name_suffix='.gz',\n",
    "          coder=example_proto_coder.ExampleProtoCoder(\n",
    "              transformed_metadata.schema))\n",
    "      \n",
    "      # Write the transformation function to a file, as well\n",
    "      _ = (transform_fn\n",
    "           | 'WriteTransformFn' >>\n",
    "           transform_fn_io.WriteTransformFn(os.path.join(OUTPUT_DIR, 'metadata')))\n",
    "\n",
    "# Preprocess the training/test data\n",
    "preprocess(in_test_mode=True, EVERY_N=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      " 4 -rw-r--r-- 1 root root  3071 Jul 10 01:20 eval-00000-of-00001.gz\n",
      " 4 drwxr-xr-x 5 root root  4096 Jul 10 01:20 metadata\n",
      " 4 drwxr-xr-x 3 root root  4096 Jul 10 01:20 tmp\n",
      "12 -rw-r--r-- 1 root root 11567 Jul 10 01:20 train-00000-of-00001.gz\n",
      "total 12\n",
      "4 drwxr-xr-x 3 root root 4096 Jul 10 01:20 rawdata_metadata\n",
      "4 drwxr-xr-x 3 root root 4096 Jul 10 01:20 transformed_metadata\n",
      "4 drwxr-xr-x 3 root root 4096 Jul 10 01:20 transform_fn\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "ls -ls preproc_tft\n",
    "ls -ls preproc_tft/metadata\n",
    "# gsutil ls -l gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/\n",
    "# gsutil ls -l gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Train off preprocessed data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Local Manual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'basic_features_dnn_classifier_tuned'\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 60, '_session_config': None, '_keep_checkpoint_max': 10, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff761bf790>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_dnn_classifier_tuned/../models/basic_features_dnn_classifier_tuned', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 60, '_session_config': None, '_keep_checkpoint_max': 10, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7eff761bf7d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_dnn_classifier_tuned/../models/basic_features_dnn_classifier_tuned', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 5 secs (eval_spec.throttle_secs) or training is finished.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_transform/saved/input_fn_maker.py:557: read_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:833: read_keyed_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:542: read_keyed_batch_examples (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:550: queue_parsed_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-07-13 16:22:04.275873: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_dnn_classifier_tuned/../models/basic_features_dnn_classifier_tuned/model.ckpt.\n",
      "INFO:tensorflow:loss = 214.56299, step = 1\n",
      "INFO:tensorflow:global_step/sec: 189.869\n",
      "INFO:tensorflow:loss = 169.72209, step = 101 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.945\n",
      "INFO:tensorflow:loss = 157.94571, step = 201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.312\n",
      "INFO:tensorflow:loss = 170.55238, step = 301 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.353\n",
      "INFO:tensorflow:loss = 146.2756, step = 401 (0.541 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_dnn_classifier_tuned/../models/basic_features_dnn_classifier_tuned/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 151.03795.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-13-16:22:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_dnn_classifier_tuned/../models/basic_features_dnn_classifier_tuned/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-13-16:22:10\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.6721311, accuracy_baseline = 0.6721312, auc = 0.3963415, auc_precision_recall = 0.29372507, average_loss = 0.91259784, f1_score = 0.0, false_negatives = 20.0, false_positives = 0.0, global_step = 500, label/mean = 0.32786885, loss = 55.66847, precision = 0.0, prediction/mean = 0.22984329, recall = 0.0, true_negatives = 41.0, true_positives = 0.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_dnn_classifier_tuned/../models/basic_features_dnn_classifier_tuned/model.ckpt-500\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_dnn_classifier_tuned/../models/basic_features_dnn_classifier_tuned/export/exporter/temp-1531498930/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUTPUT_DIR=${PWD}/../models/${MODEL_NAME}\n",
    "rm -rf ${OUTPUT_DIR}\n",
    "export PYTHONPATH=${PYTHONPATH}:$PWD/trainer\n",
    "python -m trainer.task \\\n",
    "   --train_data_paths=\"${PWD}/preproc_tft/train*\" \\\n",
    "   --eval_data_paths=\"${PWD}/preproc_tft/eval*\" \\\n",
    "   --train_batch_size=${TRAIN_N} \\\n",
    "   --train_steps=500 \\\n",
    "   --eval_steps=1 \\\n",
    "   --output_dir=${OUTPUT_DIR} \\\n",
    "   --job-dir=/tmp \\\n",
    "   --metadata_path=\"${PWD}/preproc_tft/metadata\" \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Results for 2500 batches of 303 cases (2500 training epochs using a `DNNClassifier`):\n",
    "\n",
    "- Accuracy = 0.6721311\n",
    "- Accuracy baseline = 0.6721312\n",
    "- AUC = 0.5\n",
    "- AUC-PR = 0.6639344\n",
    "- Average loss = 0.64499277\n",
    "- F1 score = 0.0\n",
    "- False negatives = 20.0\n",
    "- False positives = 0.0\n",
    "- Label/mean = 0.32786885\n",
    "- Loss = 39.34456\n",
    "- Precision = 0.0\n",
    "- Prediction/mean = 0.25737455\n",
    "- Recall = 0.0\n",
    "- True negatives = 41.0\n",
    "- True positives = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Local ML Engine Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {}, u'job': {u'args': [u'--train_data_paths=/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/preproc_tft/train*', u'--eval_data_paths=/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/preproc_tft/eval*', u'--train_steps=2500', u'--train_batch_size=303', u'--eval_steps=1', u'--output_dir=/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier', u'--metadata_path=/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/preproc_tft/metadata/', u'--job-dir', u'/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier'], u'job_name': u'trainer.task'}, u'task': {}}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 60, '_session_config': None, '_keep_checkpoint_max': 10, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f10276261d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 60, '_session_config': None, '_keep_checkpoint_max': 10, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1027626210>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 5 secs (eval_spec.throttle_secs) or training is finished.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow_transform/saved/input_fn_maker.py:557: read_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:833: read_keyed_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:542: read_keyed_batch_examples (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:550: queue_parsed_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-07-10 01:25:38.211488: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:loss = 207.53297, step = 1\n",
      "INFO:tensorflow:global_step/sec: 127.823\n",
      "INFO:tensorflow:loss = 230.3078, step = 101 (0.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.798\n",
      "INFO:tensorflow:loss = 47.643623, step = 201 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.066\n",
      "INFO:tensorflow:loss = 4.7031493, step = 301 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.097\n",
      "INFO:tensorflow:loss = 2.685412, step = 401 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.538\n",
      "INFO:tensorflow:loss = 1.3279488, step = 501 (0.612 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 532 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.7140055.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-10-01:25:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-532\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-10-01:25:45\n",
      "INFO:tensorflow:Saving dict for global step 532: accuracy = 0.5081967, accuracy_baseline = 0.6721312, auc = 0.4237805, auc_precision_recall = 0.26538604, average_loss = 3.7130513, f1_score = 0.0625, false_negatives = 19.0, false_positives = 11.0, global_step = 532, label/mean = 0.32786885, loss = 226.49612, precision = 0.083333336, prediction/mean = 0.21082851, recall = 0.05, true_negatives = 30.0, true_positives = 1.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-532\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/export/exporter/temp-1531185946/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-532\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 533 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4502897, step = 533\n",
      "INFO:tensorflow:global_step/sec: 122.056\n",
      "INFO:tensorflow:loss = 1.2887813, step = 633 (0.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.044\n",
      "INFO:tensorflow:loss = 0.46162528, step = 733 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.012\n",
      "INFO:tensorflow:loss = 0.46781436, step = 833 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.447\n",
      "INFO:tensorflow:loss = 0.21921995, step = 933 (0.643 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1031 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.23044838.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-10-01:25:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-1031\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-10-01:25:55\n",
      "INFO:tensorflow:Saving dict for global step 1031: accuracy = 0.5081967, accuracy_baseline = 0.6721312, auc = 0.43170735, auc_precision_recall = 0.2923492, average_loss = 4.4782596, f1_score = 0.0625, false_negatives = 19.0, false_positives = 11.0, global_step = 1031, label/mean = 0.32786885, loss = 273.17383, precision = 0.083333336, prediction/mean = 0.20970173, recall = 0.05, true_negatives = 30.0, true_positives = 1.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-1031\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/export/exporter/temp-1531185955/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-1031\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1032 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.34126753, step = 1032\n",
      "INFO:tensorflow:global_step/sec: 124.822\n",
      "INFO:tensorflow:loss = 0.15592404, step = 1132 (0.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.555\n",
      "INFO:tensorflow:loss = 0.16645561, step = 1232 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.15\n",
      "INFO:tensorflow:loss = 0.105608985, step = 1332 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.321\n",
      "INFO:tensorflow:loss = 0.20981959, step = 1432 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.983\n",
      "INFO:tensorflow:loss = 0.1495998, step = 1532 (0.645 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1544 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.109895684.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-10-01:26:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-1544\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-10-01:26:04\n",
      "INFO:tensorflow:Saving dict for global step 1544: accuracy = 0.5081967, accuracy_baseline = 0.6721312, auc = 0.42804882, auc_precision_recall = 0.28821015, average_loss = 4.8660507, f1_score = 0.0625, false_negatives = 19.0, false_positives = 11.0, global_step = 1544, label/mean = 0.32786885, loss = 296.8291, precision = 0.083333336, prediction/mean = 0.20923781, recall = 0.05, true_negatives = 30.0, true_positives = 1.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-1544\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/export/exporter/temp-1531185964/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-1544\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1545 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.10847333, step = 1545\n",
      "INFO:tensorflow:global_step/sec: 123.9\n",
      "INFO:tensorflow:loss = 0.065146744, step = 1645 (0.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.359\n",
      "INFO:tensorflow:loss = 0.04832537, step = 1745 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.462\n",
      "INFO:tensorflow:loss = 0.093249395, step = 1845 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.892\n",
      "INFO:tensorflow:loss = 0.08693374, step = 1945 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.405\n",
      "INFO:tensorflow:loss = 0.054525446, step = 2045 (0.635 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2074 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.059832033.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-10-01:26:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-2074\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-10-01:26:13\n",
      "INFO:tensorflow:Saving dict for global step 2074: accuracy = 0.5081967, accuracy_baseline = 0.6721312, auc = 0.43597564, auc_precision_recall = 0.29205534, average_loss = 5.123264, f1_score = 0.0625, false_negatives = 19.0, false_positives = 11.0, global_step = 2074, label/mean = 0.32786885, loss = 312.5191, precision = 0.083333336, prediction/mean = 0.20943707, recall = 0.05, true_negatives = 30.0, true_positives = 1.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-2074\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/export/exporter/temp-1531185973/saved_model.pb\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-2074\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2075 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.04976847, step = 2075\n",
      "INFO:tensorflow:global_step/sec: 124.554\n",
      "INFO:tensorflow:loss = 0.059646364, step = 2175 (0.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.118\n",
      "INFO:tensorflow:loss = 0.029310497, step = 2275 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.278\n",
      "INFO:tensorflow:loss = 0.03233996, step = 2375 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.189\n",
      "INFO:tensorflow:loss = 0.023438165, step = 2475 (0.625 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2500 into /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.045802403.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-10-01:26:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-2500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-10-01:26:21\n",
      "INFO:tensorflow:Saving dict for global step 2500: accuracy = 0.5081967, accuracy_baseline = 0.6721312, auc = 0.4359756, auc_precision_recall = 0.2920964, average_loss = 5.2682295, f1_score = 0.0625, false_negatives = 19.0, false_positives = 11.0, global_step = 2500, label/mean = 0.32786885, loss = 321.362, precision = 0.083333336, prediction/mean = 0.20961416, recall = 0.05, true_negatives = 30.0, true_positives = 1.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'age': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'activity': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/model.ckpt-2500\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/notebooks/eim-analysis/Hallelujah_Effect/basic_features_hyperparameter_tuning/../models/basic_features_basic_dnn_classifier/export/exporter/temp-1531185982/saved_model.pb\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-10 01:25:34.008798. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUTPUT_DIR=${PWD}/../models/${MODEL_NAME}\n",
    "rm -rf ${OUTPUT_DIR}\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/trainer/trainer \\\n",
    "   --job-dir=$OUTPUT_DIR \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"${PWD}/preproc_tft/train*\" \\\n",
    "   --eval_data_paths=\"${PWD}/preproc_tft/eval*\" \\\n",
    "   --train_steps=2500 \\\n",
    "   --train_batch_size=${TRAIN_N} \\\n",
    "   --eval_steps=1 \\\n",
    "   --output_dir=${OUTPUT_DIR} \\\n",
    "   --metadata_path=\"${PWD}/preproc_tft/metadata/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create hyper-parameter configuration\n",
    "\n",
    "The file specifies the search region in parameter space.  Cloud MLE carries out a smart search algorithm within these constraints (i.e. it does not try out every single value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  scaleTier: STANDARD_1\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    maxTrials: 1000\n",
    "    maxParallelTrials: 5\n",
    "    hyperparameterMetricTag: f1_score\n",
    "    params:\n",
    "    - parameterName: train_steps\n",
    "      type: DISCRETE\n",
    "      discreteValues: [500, 5000, 10000, 20000, 30000, 50000]\n",
    "    - parameterName: hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"128 32 4\", \"256 128 16\", \"64 64 64 8\", \"16 8 4\"]\n",
    "    - parameterName: dropout\n",
    "      type: DISCRETE\n",
    "      discreteValues: [0., 0.25, 0.5, 0.75]\n",
    "    - parameterName: learning_rate\n",
    "      type: DISCRETE\n",
    "      discreteValues: [0.001, 0.01, 0.1, 0.25, 0.5]\n",
    "    - parameterName: activation_function\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: [\"relu\", \"leaky_relu\", \"elu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cloud ML Engine Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://eim-muse/analysis/hallelujah-effect/models/basic_features_dnn_classifier_tuned us-central1 hallelujah_effect180713_162309\n",
      "jobId: hallelujah_effect180713_162309\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [hallelujah_effect180713_162309] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hallelujah_effect180713_162309\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hallelujah_effect180713_162309\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUTPUT_DIR=gs://${BUCKET}/analysis/hallelujah-effect/models/${MODEL_NAME}\n",
    "JOBNAME=hallelujah_effect$(date -u +%y%m%d_%H%M%S)\n",
    "echo ${OUTPUT_DIR} $REGION $JOBNAME\n",
    "gsutil -m rm -rf ${OUTPUT_DIR}\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --package-path=${PWD}/trainer/trainer \\\n",
    "   --module-name=trainer.task \\\n",
    "   --job-dir=${OUTPUT_DIR} \\\n",
    "   --scale-tier=STANDARD_1 \\\n",
    "   --runtime-version=1.8 \\\n",
    "   --config=hyperparam.yaml \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/eval*\" \\\n",
    "   --output_dir=$OUTPUT_DIR \\\n",
    "   --train_steps=25 \\\n",
    "   --train_batch_size=${TRAIN_N} \\\n",
    "   --eval_steps=1 \\\n",
    "   --metadata_path=gs://${BUCKET}/analysis/hallelujah-effect/preproc_tft/metadata/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Results for 2500 batches of 303 cases (2500 training epochs using a `DNNClassifier`):\n",
    "\n",
    "- Accuracy = 0.55737704\n",
    "- Accuracy baseline = 0.6721312\n",
    "- AUC = 0.4573171\n",
    "- AUC-PR = 0.30257925\n",
    "- Average loss = 13.65598\n",
    "- F1 score = 0.12903225\n",
    "- False negatives = 18.0\n",
    "- False positives = 9.0\n",
    "- Label/mean = 0.32786885\n",
    "- Loss = 833.0148\n",
    "- Precision = 0.18181819\n",
    "- Prediction/mean = 0.190581\n",
    "- Recall = 0.1\n",
    "- True negatives = 32.0\n",
    "- True positives = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## View Results in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4344. Click <a href=\"/_proxy/40591/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4344"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://eim-muse/analysis/hallelujah-effect/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TensorBoard.stop(327)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%writefile /tmp/test.json\n",
    "{\"age\":\"29.0\",\"activity\":3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "model_dir=$(ls $PWD/hallelujah-effect_trained/export/exporter/)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=./hallelujah-effect_trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=/tmp/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# To Do\n",
    "\n",
    "- Double-check that Dublin ratings are inverted properly\n",
    "- LASSO to identify important features\n",
    "- Hyperparameter search\n",
    "- More plots and statistics from the dataset with which I'm working here\n",
    "- Bring in rows with missing values\n",
    "- Feature engineering (physiological signals, MIR, feature crosses, variable-width binning)\n",
    "- Include signals with good quality only in reaction range\n",
    "- Customize estimator to add additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://eim-muse/analysis/hallelujah-effect/models/basic_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-01 20:34:08.418586. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "print('gs://{}/analysis/hallelujah-effect/models/{}'.format(BUCKET, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing event files... (this can take a few minutes)\n",
      "======================================================================\n",
      "\n",
      "Found event files in:\n",
      "gs://eim-muse/analysis/hallelujah-effect/models/basic_features\n",
      "gs://eim-muse/analysis/hallelujah-effect/models/basic_features/eval/\n",
      "\n",
      "These tags are in gs://eim-muse/analysis/hallelujah-effect/models/basic_features:\n",
      "audio -\n",
      "histograms\n",
      "   dnn/dnn/hiddenlayer_0/activation\n",
      "   dnn/dnn/hiddenlayer_1/activation\n",
      "   dnn/dnn/hiddenlayer_2/activation\n",
      "   dnn/dnn/logits/activation\n",
      "images -\n",
      "scalars\n",
      "   average_loss\n",
      "   dnn/dnn/hiddenlayer_0/fraction_of_zero_values\n",
      "   dnn/dnn/hiddenlayer_1/fraction_of_zero_values\n",
      "   dnn/dnn/hiddenlayer_2/fraction_of_zero_values\n",
      "   dnn/dnn/logits/fraction_of_zero_values\n",
      "   loss\n",
      "   read_batch_features/file_name_queue/fraction_of_32_full\n",
      "   read_batch_features/fraction_over_9970_of_30_full\n",
      "   read_batch_features/queue/parsed_features/read_batch_features/fifo_queue/fraction_of_100_full\n",
      "tensor -\n",
      "======================================================================\n",
      "\n",
      "Event statistics for gs://eim-muse/analysis/hallelujah-effect/models/basic_features:\n",
      "audio -\n",
      "graph\n",
      "   first_step           0\n",
      "   last_step            0\n",
      "   max_step             0\n",
      "   min_step             0\n",
      "   num_steps            1\n",
      "   outoforder_steps     []\n",
      "histograms\n",
      "   first_step           1\n",
      "   last_step            1\n",
      "   max_step             1\n",
      "   min_step             1\n",
      "   num_steps            1\n",
      "   outoforder_steps     []\n",
      "images -\n",
      "scalars\n",
      "   first_step           1\n",
      "   last_step            1\n",
      "   max_step             1\n",
      "   min_step             1\n",
      "   num_steps            1\n",
      "   outoforder_steps     []\n",
      "sessionlog:checkpoint\n",
      "   first_step           1\n",
      "   last_step            8\n",
      "   max_step             8\n",
      "   min_step             1\n",
      "   num_steps            8\n",
      "   outoforder_steps     []\n",
      "sessionlog:start\n",
      "   outoforder_steps     []\n",
      "   steps                [1L]\n",
      "sessionlog:stop -\n",
      "tensor -\n",
      "======================================================================\n",
      "\n",
      "These tags are in gs://eim-muse/analysis/hallelujah-effect/models/basic_features/eval/:\n",
      "audio -\n",
      "histograms -\n",
      "images -\n",
      "scalars\n",
      "   accuracy\n",
      "   accuracy_baseline\n",
      "   auc\n",
      "   auc_precision_recall\n",
      "   average_loss\n",
      "   label/mean\n",
      "   loss\n",
      "   prediction/mean\n",
      "tensor -\n",
      "======================================================================\n",
      "\n",
      "Event statistics for gs://eim-muse/analysis/hallelujah-effect/models/basic_features/eval/:\n",
      "audio -\n",
      "graph\n",
      "   first_step           0\n",
      "   last_step            0\n",
      "   max_step             0\n",
      "   min_step             0\n",
      "   num_steps            1\n",
      "   outoforder_steps     []\n",
      "histograms -\n",
      "images -\n",
      "scalars\n",
      "   first_step           1\n",
      "   last_step            14\n",
      "   max_step             14\n",
      "   min_step             1\n",
      "   num_steps            14\n",
      "   outoforder_steps     []\n",
      "sessionlog:checkpoint -\n",
      "sessionlog:start -\n",
      "sessionlog:stop -\n",
      "tensor -\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "tensorboard --inspect --logdir gs://eim-muse/analysis/hallelujah-effect/models/basic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/simplejson/encoder.py:286: DeprecationWarning: Interpreting naive datetime as local 2018-07-04 00:58:42.778246. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "ml = \"\"\"\n",
    "This is\n",
    "a\n",
    "multiline string.\n",
    "\"\"\"\n",
    "\n",
    "with open('./test.txt', 'w') as file:\n",
    "  file.write(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
